{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "#### Building in house evaluaion metrics for our models such as Fscore, Precesion and Recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Calculates the precision of the predicted labels\n",
    "def get_precision(y_pred, y_test1, debug = False):\n",
    "    # deal with npdarray\n",
    "    y_pred = list(y_pred)\n",
    "    y_true = list(y_test1)\n",
    "    #---------\n",
    "    n = len(y_pred);\n",
    "    y_pred = [0 if v is None else v for v in y_pred]# deal with None type\n",
    "    y_true = [0 if v is None else v for v in y_test1]# deal with None type\n",
    "    true_positive = sum(y_pred[i]* y_test1[i] for i in range(n))\n",
    "    if (0 == sum(y_pred)): return 0\n",
    "    return true_positive*1.0/sum(y_pred)\n",
    "    \n",
    "## Calculates the recall of the predicted labels\n",
    "def get_recall(y_pred, y_test1):\n",
    "    # deal with npdarray\n",
    "    y_pred = list(y_pred)\n",
    "    y_true = list(y_test1)\n",
    "    #---------\n",
    "    n = len(y_pred);\n",
    "    y_pred = list(map(int,[1 == l for l in y_test1]))# deal with None type\n",
    "    y_true = list(map(int,[1 == l for l in y_test1]))# deal with None type\n",
    "    true_positive = sum(y_pred[i]*y_test1[i] for i in range(n))\n",
    "    if 0 == sum(y_test): return 0\n",
    "    return true_positive*1.0/sum(y_test1)\n",
    "    \n",
    "\n",
    "## Calculates the f-score of the predicted labels\n",
    "def get_fscore(y_pred, y_test1):\n",
    "    precision = get_precision(y_pred, y_test1);\n",
    "    if (0 == precision): return 0\n",
    "    recall= get_recall(y_pred, y_test1);\n",
    "    if (0 == recall): return 0\n",
    "    beta = 1.0;\n",
    "    # print(\"get_fscore:\",(beta**2*precision+recall))\n",
    "    fscore = (beta**2+1)*precision*recall/(beta**2*precision+recall);\n",
    "    return fscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading feat files, transform and observe them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import requests\n",
    "\n",
    "#filename = 'aclImdb_v1.tar.gz'\n",
    "#url = u'http://ai.stanford.edu/~amaas/data/sentiment/' + filename\n",
    "#r = requests.get(url)\n",
    "#with open(filename, 'wb') as f:\n",
    "    #f.write(r.content)\n",
    "\n",
    "# ...extract zip file\n",
    "#import tarfile\n",
    "\n",
    "#tar = tarfile.open(filename, mode='r')\n",
    "#tar.extractall()\n",
    "#tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.,  7.,  9., ...,  4.,  2.,  2.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load Files and divide them features and labels\n",
    "import sklearn\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "X_test, y_test = load_svmlight_file(\"Test_labeledBow.feat\")\n",
    "X_train, y_train = load_svmlight_file(\"Train_labeledBow.feat\")\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Labels are given in review score turning them binary by given threshold\n",
    "y_test= np.where(y_test <= 4, 0, 1)\n",
    "y_train=np.where(y_train <= 4, 0, 1)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#changing dtype for efficient memory usage \n",
    "import scipy.sparse._sparsetools\n",
    "import scipy\n",
    "X_test=scipy.sparse.lil_matrix(X_test, dtype='uint16')\n",
    "X_train=scipy.sparse.lil_matrix(X_train, dtype='uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing to array as our test and train data in sparse matrix \n",
    "X_test_array=X_test.toarray()\n",
    "X_train_array=X_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>89517</th>\n",
       "      <th>89518</th>\n",
       "      <th>89519</th>\n",
       "      <th>89520</th>\n",
       "      <th>89521</th>\n",
       "      <th>89522</th>\n",
       "      <th>89523</th>\n",
       "      <th>89524</th>\n",
       "      <th>89525</th>\n",
       "      <th>89526</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89527 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4      5      6      7      8      9      \\\n",
       "0      9      1      4      4      6      4      2      2      4      0   \n",
       "1      7      4      2      2      0      4      1      0      2      2   \n",
       "2      4      4      4      7      2      1      1      1      0      1   \n",
       "3     10      2      2      0      3      2      4      2      0      1   \n",
       "4     13      9      6      4      2      5     10      6      0      2   \n",
       "\n",
       "   ...    89517  89518  89519  89520  89521  89522  89523  89524  89525  89526  \n",
       "0  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "1  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "2  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "3  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "4  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 89527 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Observing train data in dataframe\n",
    "train_df=pd.DataFrame(X_train_array)\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>89513</th>\n",
       "      <th>89514</th>\n",
       "      <th>89515</th>\n",
       "      <th>89516</th>\n",
       "      <th>89517</th>\n",
       "      <th>89518</th>\n",
       "      <th>89519</th>\n",
       "      <th>89520</th>\n",
       "      <th>89521</th>\n",
       "      <th>89522</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89523 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4      5      6      7      8      9      \\\n",
       "0      7      4      2      5      5      1      3      1      6      3   \n",
       "1      9      4      4      0      3      1     10      1     12      1   \n",
       "2     21      7      4      5      7      8      0      5      8      4   \n",
       "3     13      5      8      8      4      2      6      4      8      2   \n",
       "4      4      1      2      1      3      2      3      2      4      4   \n",
       "\n",
       "   ...    89513  89514  89515  89516  89517  89518  89519  89520  89521  89522  \n",
       "0  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "1  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "2  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "3  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "4  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 89523 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Observing test data in dataframe\n",
    "test_df=pd.DataFrame(X_test_array)\n",
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>89517</th>\n",
       "      <th>89518</th>\n",
       "      <th>89519</th>\n",
       "      <th>89520</th>\n",
       "      <th>89521</th>\n",
       "      <th>89522</th>\n",
       "      <th>89523</th>\n",
       "      <th>89524</th>\n",
       "      <th>89525</th>\n",
       "      <th>89526</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89527 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0  1  2  3  4  5   6  7   8  9  ...    89517  89518  89519  89520  89521  \\\n",
       "0   7  4  2  5  5  1   3  1   6  3  ...        0      0      0      0      0   \n",
       "1   9  4  4  0  3  1  10  1  12  1  ...        0      0      0      0      0   \n",
       "2  21  7  4  5  7  8   0  5   8  4  ...        0      0      0      0      0   \n",
       "3  13  5  8  8  4  2   6  4   8  2  ...        0      0      0      0      0   \n",
       "4   4  1  2  1  3  2   3  2   4  4  ...        0      0      0      0      0   \n",
       "\n",
       "   89522  89523  89524  89525  89526  \n",
       "0      0      0      0      0      0  \n",
       "1      0      0      0      0      0  \n",
       "2      0      0      0      0      0  \n",
       "3      0      0      0      0      0  \n",
       "4      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 89527 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As you can see test data is less in columns thus we add default columns so that our test data will be suitable for model impl.\n",
    "test_df['89523']='0'\n",
    "test_df['89524']='0'\n",
    "test_df['89525']='0'\n",
    "test_df['89526']='0'\n",
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 \n",
    "### Majority Baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fscore : 0.666666666667\n",
      "Recall 1.0\n",
      "Precesion 0.5\n"
     ]
    }
   ],
   "source": [
    "#in this question we will use Majority Baseline Model. \n",
    "#As data is even between neg and pos reviews we assign majority reviews as pos\n",
    "#The label for the test data would be the majority class found in training data that is positive as we assigned\n",
    "y_pred = [1]*len(test_df)\n",
    "#Evaluating model performance\n",
    "print('Fscore :', get_fscore(y_pred, y_test))\n",
    "print('Recall', get_recall(y_pred, y_test))\n",
    "print('Precesion',get_precision(y_pred, y_test, debug = False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "### Length Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing threshold that maximizes accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review_length_threshold(df, label, plot_flag = True):\n",
    "    ## YOUR CODE HERE\n",
    "    # print(\"load training file\")\n",
    "    #words,labels = load_file(training_file, True)\n",
    "    Dict_len = defaultdict(set)\n",
    "    for w in df: Dict_len[w].add(w)\n",
    "    # Evaluation depending on fscore\n",
    "    Min = min(Dict_len)\n",
    "    Max = max(Dict_len) \n",
    "    ThreRange=  range(Min,Max+1)\n",
    "    FscoreL = dict([(f1_score(list(map(int,[w > Thres for w in df])), label, average=\"macro\"),Thres) for Thres in ThreRange])\n",
    "    Thres_opt = FscoreL[max(FscoreL)]\n",
    "    if plot_flag:\n",
    "         print(\"Range of thresholds:\",Min,\"to\",Max, \" with optimal threshold:\", Thres_opt+1)\n",
    "    del df\n",
    "    del label\n",
    "    return ThreRange, Thres_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    138\n",
       "1    114\n",
       "2    115\n",
       "3    104\n",
       "4    232\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_length=train_df.sum(axis=1)\n",
    "train_df_length.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of thresholds: 10 to 2476  with optimal threshold: 194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/py3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(range(10, 2477), 193)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_length_threshold(train_df_length, y_train, plot_flag = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Length for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([138, 114, 115, ..., 231, 153, 138], dtype=uint64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_array=X_train_array.sum(axis=1)\n",
    "X_train_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=np.where(X_train_array < 194, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fscore : 0.671514852706\n",
      "Recall 1.0\n",
      "Precesion 0.505474113936\n"
     ]
    }
   ],
   "source": [
    "print('Fscore :', get_fscore(data2, y_train))\n",
    "print('Recall', get_recall(data2, y_train))\n",
    "print('Precesion',get_precision(data2, y_train, debug = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Length for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([152, 141, 302, ..., 258, 167, 142], dtype=uint64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_array=X_test_array.sum(axis=1)\n",
    "X_test_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test=np.where(X_test_array < 194, 0, 1)\n",
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fscore : 0.659937888199\n",
      "Recall 1.0\n",
      "Precesion 0.492468134415\n"
     ]
    }
   ],
   "source": [
    "print('Fscore :', get_fscore(data_test, y_test))\n",
    "print('Recall', get_recall(data_test, y_test))\n",
    "print('Precesion',get_precision(data_test, y_test, debug = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive-Bayes Classifier\n"
     ]
    }
   ],
   "source": [
    "#initialize NB classifier\n",
    "print(\"Naive-Bayes Classifier\")\n",
    "nb = GaussianNB()\n",
    "#fit your classifier to training set\n",
    "nb = nb.fit(train_df[:15000], y_train[:15000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = nb.predict(test_df[:15000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fscore : 0.915222562012\n",
      "Recall 1.0\n",
      "Precesion 0.843696162882\n"
     ]
    }
   ],
   "source": [
    "print('Fscore :', get_fscore(y_pred1, y_test[:15000]))\n",
    "print('Recall', get_recall(y_pred1, y_test[:15000]))\n",
    "print('Precesion',get_precision(y_pred1, y_test[:15000], debug = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.53\n",
      "Recall:  0.53\n",
      "F1-score:  0.53\n",
      "Very good it is identical\n"
     ]
    }
   ],
   "source": [
    "# I want to check whether my evaluation metrics is true or not with build in function from sklearn\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, accuracy_score,classification_report\n",
    "#compare y_pred with actual targets for  test set(y_test) and calculate precision, recall, f1-score\n",
    "print(\"Precision: %0.2f\" %precision_score(y_test[:15000], y_pred1 , average=\"macro\"))\n",
    "print(\"Recall:  %0.2f\" %recall_score(y_test[:15000], y_pred1 , average=\"macro\"))\n",
    "print(\"F1-score:  %0.2f\" %f1_score(y_test[:15000], y_pred1 , average=\"macro\"))\n",
    "print('Very good it is identical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5\n",
    "### Decision Tree Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree Classifier\n",
    "print(\"Decision Tree Classifier\")\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "dt = dt.fit(train_df[:15000], y_train[:15000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dt.predict(test_df[:15000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fscore : 1.0\n",
      "Recall 1.0\n",
      "Precesion 1.0\n"
     ]
    }
   ],
   "source": [
    "print('Fscore :', get_fscore(y_pred, y_test[:15000]))\n",
    "print('Recall', get_recall(y_pred, y_test[:15000]))\n",
    "print('Precesion',get_precision(y_pred, y_test[:15000], debug = False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.00\n",
      "Recall:  1.00\n",
      "F1-score:  1.00\n",
      "Very good it is identical\n"
     ]
    }
   ],
   "source": [
    "# I want to check whether my evaluation metrics is true or not with build in function from sklearn\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, accuracy_score,classification_report\n",
    "#compare y_pred with actual targets for  test set(y_test) and calculate precision, recall, f1-score\n",
    "print(\"Precision: %0.2f\" %precision_score(y_test[:15000], y_pred , average=\"macro\"))\n",
    "print(\"Recall:  %0.2f\" %recall_score(y_test[:15000], y_pred , average=\"macro\"))\n",
    "print(\"F1-score:  %0.2f\" %f1_score(y_test[:15000], y_pred , average=\"macro\"))\n",
    "print('Very good it is identical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-05c993ae4458>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "\n",
    "import gensim \n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\programdata\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (1.2.1)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (1.16.4)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (1.8.4)\n",
      "Requirement already satisfied: boto>=2.32 in c:\\programdata\\anaconda3\\lib\\site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from smart-open>=1.8.1->gensim) (2.22.0)\n",
      "Requirement already satisfied: boto3 in c:\\programdata\\anaconda3\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.9.243)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2019.6.16)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.243 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.8.1->gensim) (1.12.243)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.8.1->gensim) (0.9.4)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.8.1->gensim) (0.2.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from botocore<1.13.0,>=1.12.243->boto3->smart-open>=1.8.1->gensim) (0.14)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in c:\\programdata\\anaconda3\\lib\\site-packages (from botocore<1.13.0,>=1.12.243->boto3->smart-open>=1.8.1->gensim) (2.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\programdata\\anaconda3\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.1.7)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.4)\n",
      "Requirement already satisfied: gast==0.2.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.8.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.33.4)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.8.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.24.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (41.0.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.15.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: h5py in c:\\programdata\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.8->tensorflow) (2.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-probability\n",
      "  Using cached https://files.pythonhosted.org/packages/f8/72/29ef1e5f386b65544d4e7002dfeca1e55b099ed182cd6d405c21a19ae259/tensorflow_probability-0.8.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: gast<0.3,>=0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-probability) (0.2.2)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-probability) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-probability) (1.16.4)\n",
      "Collecting cloudpickle==1.1.1 (from tensorflow-probability)\n",
      "  Using cached https://files.pythonhosted.org/packages/24/fb/4f92f8c0f40a0d728b4f3d5ec5ff84353e705d8ff5e3e447620ea98b06bd/cloudpickle-1.1.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: decorator in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-probability) (4.4.0)\n",
      "Installing collected packages: cloudpickle, tensorflow-probability\n",
      "  Found existing installation: cloudpickle 1.2.1\n",
      "    Uninstalling cloudpickle-1.2.1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: spyder 3.3.6 requires pyqt5<5.13; python_version >= \"3\", which is not installed.\n",
      "ERROR: spyder 3.3.6 requires pyqtwebengine<5.13; python_version >= \"3\", which is not installed.\n",
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Access is denied: 'c:\\\\programdata\\\\anaconda3\\\\lib\\\\site-packages\\\\cloudpickle-1.2.1.dist-info\\\\INSTALLER'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " import tensorflow.python.ops.linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gensim Version: 3.8.1\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import gensim\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "import tensorflow as tf\n",
    "#from tensorflow import projector\n",
    "\n",
    "print('gensim Version: %s' % (gensim.__version__))\n",
    "\n",
    "class WordEmbedding:\n",
    "    __author__ = \"Edward Ma\"\n",
    "    __copyright__ = \"Copyright 2018, Edward Ma\"\n",
    "    __credits__ = [\"Edward Ma\"]\n",
    "    __license__ = \"Apache\"\n",
    "    __version__ = \"2.0\"\n",
    "    __maintainer__ = \"Edward Ma\"\n",
    "    __email__ = \"makcedward@gmail.com\"\n",
    "\n",
    "    def __init__(self, verbose=0):\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.model = {}\n",
    "        \n",
    "    def convert(self, source, ipnut_file_path, output_file_path):\n",
    "        if source == 'glove':\n",
    "            input_file = datapath(ipnut_file_path)\n",
    "            output_file = get_tmpfile(output_file_path)\n",
    "            glove2word2vec(input_file, output_file)\n",
    "        elif source == 'word2vec':\n",
    "            pass\n",
    "        elif source == 'fasttext':\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError('Possible value of source are glove, word2vec, fasttext')\n",
    "        \n",
    "    def load(self, source, file_path):\n",
    "        print(datetime.datetime.now(), 'start: loading', source)\n",
    "        if source == 'glove':\n",
    "            self.model[source] = gensim.models.KeyedVectors.load_word2vec_format(file_path)\n",
    "        elif source == 'word2vec':\n",
    "            self.model[source] = gensim.models.KeyedVectors.load_word2vec_format(file_path, binary=True)\n",
    "        elif source == 'fasttext':\n",
    "            self.model[source] = gensim.models.wrappers.FastText.load_fasttext_format(file_path)\n",
    "        else:\n",
    "            raise ValueError('Possible value of source are glove, word2vec, fasttext')\n",
    "            \n",
    "        print(datetime.datetime.now(), 'end: loading', source)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def get_model(self, source):\n",
    "        if source not in ['glove', 'word2vec', 'fasttext']:\n",
    "            raise ValueError('Possible value of source are glove, word2vec, fasttext')\n",
    "            \n",
    "        return self.model[source]\n",
    "    \n",
    "    def get_words(self, source, size=None):\n",
    "        if source not in ['glove', 'word2vec', 'fasttext']:\n",
    "            raise ValueError('Possible value of source are glove, word2vec, fasttext')\n",
    "        \n",
    "        if source in ['glove', 'word2vec']:\n",
    "            if size is None:\n",
    "                return [w for w in self.get_model(source=source).vocab]\n",
    "            else:\n",
    "                results = []\n",
    "                for i, word in enumerate(self.get_model(source=source).vocab):\n",
    "                    if i >= size:\n",
    "                        break\n",
    "                        \n",
    "                    results.append(word)\n",
    "                return results\n",
    "            \n",
    "        elif source in ['fasttext']:\n",
    "            if size is None:\n",
    "                return [w for w in self.get_model(source=source).wv.vocab]\n",
    "            else:\n",
    "                results = []\n",
    "                for i, word in enumerate(self.get_model(source=source).wv.vocab):\n",
    "                    if i >= size:\n",
    "                        break\n",
    "                        \n",
    "                    results.append(word)\n",
    "                return results\n",
    "        \n",
    "        return Exception('Unexpected flow')\n",
    "    \n",
    "    def get_dimension(self, source):\n",
    "        if source not in ['glove', 'word2vec', 'fasttext']:\n",
    "            raise ValueError('Possible value of source are glove, word2vec, fasttext')\n",
    "        \n",
    "        if source in ['glove', 'word2vec']:\n",
    "            return self.get_model(source=source).vectors[0].shape[0]\n",
    "            \n",
    "        elif source in ['fasttext']:\n",
    "            word = self.get_words(source=source, size=1)[0]\n",
    "            return self.get_model(source=source).wv[word].shape[0]\n",
    "        \n",
    "        return Exception('Unexpected flow')\n",
    "    \n",
    "    def get_vectors(self, source, words=None):\n",
    "        if source not in ['glove', 'word2vec', 'fasttext']:\n",
    "            raise ValueError('Possible value of source are glove, word2vec, fasttext')\n",
    "        \n",
    "        if source in ['glove', 'word2vec', 'fasttext']:\n",
    "            if words is None:\n",
    "                words = self.get_words(source=source)\n",
    "            \n",
    "            embedding = np.empty((len(words), self.get_dimension(source=source)), dtype=np.float32)            \n",
    "            for i, word in enumerate(words):\n",
    "                embedding[i] = self.get_vector(source=source, word=word)\n",
    "                \n",
    "            return embedding\n",
    "        \n",
    "        return Exception('Unexpected flow')\n",
    "    \n",
    "    def get_vector(self, source, word, oov=None):\n",
    "        if source not in ['glove', 'word2vec', 'fasttext']:\n",
    "            raise ValueError('Possible value of source are glove, word2vec, fasttext')\n",
    "            \n",
    "        if source not in self.model:\n",
    "            raise ValueError('Did not load %s model yet' % source)\n",
    "        \n",
    "        try:\n",
    "            return self.model[source][word]\n",
    "        except KeyError as e:\n",
    "            raise\n",
    "            \n",
    "            #TODO\n",
    "#             if oov is None:\n",
    "#                 raise\n",
    "            \n",
    "#             if 'not in vocabulary' in str(e):\n",
    "#                 if oov == ''\n",
    "\n",
    "    def build_visual_metadata(self, embedding, words, file_dir, \n",
    "                              metadata_name='metadata.csv', project_model_name='model.ckpt'):\n",
    "        # Create output directory if not exist\n",
    "        if not os.path.exists(file_dir):\n",
    "            os.makedirs(file_dir)\n",
    "\n",
    "        # Build graph\n",
    "        tf.reset_default_graph()\n",
    "        sess = tf.InteractiveSession()\n",
    "\n",
    "        embedding_graph = tf.Variable([0.0], name='embedding')\n",
    "        place = tf.placeholder(tf.float32, shape=embedding.shape)\n",
    "\n",
    "        set_embedding_graph = tf.assign(embedding_graph, place, validate_shape=False)\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(set_embedding_graph, feed_dict={place: embedding})\n",
    "\n",
    "        # Build metadata\n",
    "        with open(os.path.join(file_dir, metadata_name), 'w') as f:\n",
    "            for word in words:\n",
    "                f.write(word + '\\n')\n",
    "\n",
    "        # Build projector\n",
    "        summary_writer = tf.summary.FileWriter(file_dir, sess.graph)\n",
    "        config = projector.ProjectorConfig()\n",
    "        embedding_conf = config.embeddings.add()\n",
    "        embedding_conf.tensor_name = 'embedding:0'\n",
    "        embedding_conf.metadata_path = metadata_name\n",
    "        projector.visualize_embeddings(summary_writer, config)\n",
    "\n",
    "        # Save model\n",
    "        saver = tf.train.Saver()\n",
    "        saver.save(sess, os.path.join(file_dir, project_model_name))\n",
    "\n",
    "        # Clear\n",
    "        sess.close()\n",
    "\n",
    "        \n",
    "downloaded_glove_file_path = '../text/stanford/glove/glove.6B.50d.txt'\n",
    "glove_file_path = '../text/stanford/glove/glove.840B.300d.vec'\n",
    "\n",
    "word2vec_file_path = '../text/google/word2vec/GoogleNews-vectors-negative300.bin'\n",
    "fasttext_file_path = '../text/facebook/fasttext/wiki.en.bin'\n",
    "\n",
    "word_embedding = WordEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-05 18:24:25.121007 start: loading word2vec\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../text/google/word2vec/GoogleNews-vectors-negative300.bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-3d8449888901>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mword_embedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWordEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mword_embedding\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'word2vec'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'../text/google/word2vec/GoogleNews-vectors-negative300.bin'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_embedding\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'word2vec'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'apple'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-f2aecdf55370>\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, source, file_path)\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKeyedVectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0msource\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'word2vec'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKeyedVectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0msource\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'fasttext'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFastText\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_fasttext_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[0;32m   1496\u001b[0m         return _load_word2vec_format(\n\u001b[0;32m   1497\u001b[0m             \u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1498\u001b[1;33m             limit=limit, datatype=datatype)\n\u001b[0m\u001b[0;32m   1499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_keras_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\utils_any2vec.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loading projection weights from %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m         \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# throws for invalid file format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, transport_params)\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m     )\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[1;34m(uri, mode, ignore_ext, buffering, encoding, errors)\u001b[0m\n\u001b[0;32m    510\u001b[0m     \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPY3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 512\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    513\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mopen_kwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../text/google/word2vec/GoogleNews-vectors-negative300.bin'"
     ]
    }
   ],
   "source": [
    "word_embedding = WordEmbedding()\n",
    "word_embedding.load(source='word2vec', file_path='../text/google/word2vec/GoogleNews-vectors-negative300.bin')\n",
    "print(word_embedding.get_vector(source='word2vec', word='apple'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
