{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "#### Building in house evaluaion metrics for our models such as Fscore, Precesion and Recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Calculates the precision of the predicted labels\n",
    "def get_precision(y_pred, y_test1, debug = False):\n",
    "    # deal with npdarray\n",
    "    y_pred = list(y_pred)\n",
    "    y_true = list(y_test1)\n",
    "    #---------\n",
    "    n = len(y_pred);\n",
    "    y_pred = [0 if v is None else v for v in y_pred]# deal with None type\n",
    "    y_true = [0 if v is None else v for v in y_test1]# deal with None type\n",
    "    true_positive = sum(y_pred[i]* y_test1[i] for i in range(n))\n",
    "    if (0 == sum(y_pred)): return 0\n",
    "    return true_positive*1.0/sum(y_pred)\n",
    "    \n",
    "## Calculates the recall of the predicted labels\n",
    "def get_recall(y_pred, y_test1):\n",
    "    # deal with npdarray\n",
    "    y_pred = list(y_pred)\n",
    "    y_true = list(y_test1)\n",
    "    #---------\n",
    "    n = len(y_pred);\n",
    "    y_pred = list(map(int,[1 == l for l in y_test1]))# deal with None type\n",
    "    y_true = list(map(int,[1 == l for l in y_test1]))# deal with None type\n",
    "    true_positive = sum(y_pred[i]*y_test1[i] for i in range(n))\n",
    "    if 0 == sum(y_test): return 0\n",
    "    return true_positive*1.0/sum(y_test1)\n",
    "    \n",
    "\n",
    "## Calculates the f-score of the predicted labels\n",
    "def get_fscore(y_pred, y_test1):\n",
    "    precision = get_precision(y_pred, y_test1);\n",
    "    if (0 == precision): return 0\n",
    "    recall= get_recall(y_pred, y_test1);\n",
    "    if (0 == recall): return 0\n",
    "    beta = 1.0;\n",
    "    # print(\"get_fscore:\",(beta**2*precision+recall))\n",
    "    fscore = (beta**2+1)*precision*recall/(beta**2*precision+recall);\n",
    "    return fscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading feat files, transform and observe them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import requests\n",
    "\n",
    "#filename = 'aclImdb_v1.tar.gz'\n",
    "#url = u'http://ai.stanford.edu/~amaas/data/sentiment/' + filename\n",
    "#r = requests.get(url)\n",
    "#with open(filename, 'wb') as f:\n",
    "    #f.write(r.content)\n",
    "\n",
    "# ...extract zip file\n",
    "#import tarfile\n",
    "\n",
    "#tar = tarfile.open(filename, mode='r')\n",
    "#tar.extractall()\n",
    "#tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.,  7.,  9., ...,  4.,  2.,  2.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load Files and divide them features and labels\n",
    "import sklearn\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "X_test, y_test = load_svmlight_file(\"Test_labeledBow.feat\")\n",
    "X_train, y_train = load_svmlight_file(\"Train_labeledBow.feat\")\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Labels are given in review score turning them binary by given threshold\n",
    "y_test= np.where(y_test <= 4, 0, 1)\n",
    "y_train=np.where(y_train <= 4, 0, 1)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#changing dtype for efficient memory usage \n",
    "import scipy.sparse._sparsetools\n",
    "import scipy\n",
    "X_test=scipy.sparse.lil_matrix(X_test, dtype='uint16')\n",
    "X_train=scipy.sparse.lil_matrix(X_train, dtype='uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Changing to array as our test and train data in sparse matrix \n",
    "X_test_array=X_test.toarray()\n",
    "X_train_array=X_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>89517</th>\n",
       "      <th>89518</th>\n",
       "      <th>89519</th>\n",
       "      <th>89520</th>\n",
       "      <th>89521</th>\n",
       "      <th>89522</th>\n",
       "      <th>89523</th>\n",
       "      <th>89524</th>\n",
       "      <th>89525</th>\n",
       "      <th>89526</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89527 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4      5      6      7      8      9      \\\n",
       "0      9      1      4      4      6      4      2      2      4      0   \n",
       "1      7      4      2      2      0      4      1      0      2      2   \n",
       "2      4      4      4      7      2      1      1      1      0      1   \n",
       "3     10      2      2      0      3      2      4      2      0      1   \n",
       "4     13      9      6      4      2      5     10      6      0      2   \n",
       "\n",
       "   ...    89517  89518  89519  89520  89521  89522  89523  89524  89525  89526  \n",
       "0  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "1  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "2  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "3  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "4  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 89527 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Observing train data in dataframe\n",
    "train_df=pd.DataFrame(X_train_array)\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>89513</th>\n",
       "      <th>89514</th>\n",
       "      <th>89515</th>\n",
       "      <th>89516</th>\n",
       "      <th>89517</th>\n",
       "      <th>89518</th>\n",
       "      <th>89519</th>\n",
       "      <th>89520</th>\n",
       "      <th>89521</th>\n",
       "      <th>89522</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89523 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4      5      6      7      8      9      \\\n",
       "0      7      4      2      5      5      1      3      1      6      3   \n",
       "1      9      4      4      0      3      1     10      1     12      1   \n",
       "2     21      7      4      5      7      8      0      5      8      4   \n",
       "3     13      5      8      8      4      2      6      4      8      2   \n",
       "4      4      1      2      1      3      2      3      2      4      4   \n",
       "\n",
       "   ...    89513  89514  89515  89516  89517  89518  89519  89520  89521  89522  \n",
       "0  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "1  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "2  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "3  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "4  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 89523 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Observing test data in dataframe\n",
    "test_df=pd.DataFrame(X_test_array)\n",
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>89517</th>\n",
       "      <th>89518</th>\n",
       "      <th>89519</th>\n",
       "      <th>89520</th>\n",
       "      <th>89521</th>\n",
       "      <th>89522</th>\n",
       "      <th>89523</th>\n",
       "      <th>89524</th>\n",
       "      <th>89525</th>\n",
       "      <th>89526</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89527 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0  1  2  3  4  5   6  7   8  9  ...    89517  89518  89519  89520  89521  \\\n",
       "0   7  4  2  5  5  1   3  1   6  3  ...        0      0      0      0      0   \n",
       "1   9  4  4  0  3  1  10  1  12  1  ...        0      0      0      0      0   \n",
       "2  21  7  4  5  7  8   0  5   8  4  ...        0      0      0      0      0   \n",
       "3  13  5  8  8  4  2   6  4   8  2  ...        0      0      0      0      0   \n",
       "4   4  1  2  1  3  2   3  2   4  4  ...        0      0      0      0      0   \n",
       "\n",
       "   89522  89523  89524  89525  89526  \n",
       "0      0      0      0      0      0  \n",
       "1      0      0      0      0      0  \n",
       "2      0      0      0      0      0  \n",
       "3      0      0      0      0      0  \n",
       "4      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 89527 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As you can see test data is less in columns thus we add default columns so that our test data will be suitable for model impl.\n",
    "test_df['89523']='0'\n",
    "test_df['89524']='0'\n",
    "test_df['89525']='0'\n",
    "test_df['89526']='0'\n",
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 \n",
    "### Majority Baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fscore : 0.666666666667\n",
      "Recall 1.0\n",
      "Precesion 0.5\n"
     ]
    }
   ],
   "source": [
    "#in this question we will use Majority Baseline Model. \n",
    "#As data is even between neg and pos reviews we assign majority reviews as pos\n",
    "#The label for the test data would be the majority class found in training data that is positive as we assigned\n",
    "y_pred = [1]*len(test_df)\n",
    "#Evaluating model performance\n",
    "print('Fscore :', get_fscore(y_pred, y_test))\n",
    "print('Recall', get_recall(y_pred, y_test))\n",
    "print('Precesion',get_precision(y_pred, y_test, debug = False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "### Length Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing threshold that maximizes accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are trying to pridict the optimal threshold so that we can get higher level of accuracy. The below function will produce the optimal range that maximizes fscore. In other words, we are assuming that the length of the review may also determine whether the review is positive or not. Therefore, rather than blindly choosing the optimal range of length of the review, we build the following function that we use later to set our threshold and also will check how far it is optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review_length_threshold(df, label, plot_flag = True):\n",
    "    ## YOUR CODE HERE\n",
    "    # print(\"load training file\")\n",
    "    #words,labels = load_file(training_file, True)\n",
    "    Dict_len = defaultdict(set)\n",
    "    for w in df: Dict_len[w].add(w)\n",
    "    # Evaluation depending on fscore\n",
    "    Min = min(Dict_len)\n",
    "    Max = max(Dict_len) \n",
    "    ThreRange=  range(Min,Max+1)\n",
    "    FscoreL = dict([(f1_score(list(map(int,[w > Thres for w in df])), label, average=\"macro\"),Thres) for Thres in ThreRange])\n",
    "    Thres_opt = FscoreL[max(FscoreL)]\n",
    "    if plot_flag:\n",
    "         print(\"Range of thresholds:\",Min,\"to\",Max, \" with optimal threshold:\", Thres_opt+1)\n",
    "    del df\n",
    "    del label\n",
    "    return ThreRange, Thres_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    138\n",
       "1    114\n",
       "2    115\n",
       "3    104\n",
       "4    232\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_length=train_df.sum(axis=1)\n",
    "train_df_length.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of thresholds: 10 to 2476  with optimal threshold: 194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/py3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(range(10, 2477), 193)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_length_threshold(train_df_length, y_train, plot_flag = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### As we can see the function produced us optimal threshold of 194, which means the text less than these threshold is considered as negative while above it is considered as positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Length for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([138, 114, 115, ..., 231, 153, 138], dtype=uint64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding up all columns for each row to get length of text for each review\n",
    "X_train_array_length=X_train_array.sum(axis=1)\n",
    "X_train_array_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train1=np.where(X_train_array_length < 194, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fscore : 0.671514852706\n",
      "Recall 1.0\n",
      "Precesion 0.505474113936\n"
     ]
    }
   ],
   "source": [
    "print('Fscore :', get_fscore(data_train1, y_train))\n",
    "print('Recall', get_recall(data_train1, y_train))\n",
    "print('Precesion',get_precision(data_train1, y_train, debug = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Case two: pos < 194, neg> 194"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#case two, Now lets imagine that all reviews less than 194 are positive and the ones more than 194 is negative\n",
    "# we assume that people write more when they did not like the moview. let us check it\n",
    "data_train2=np.where(X_train_array_length < 194, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fscore : 0.662968882204\n",
      "Recall 1.0\n",
      "Precesion 0.49585149768\n"
     ]
    }
   ],
   "source": [
    "print('Fscore :', get_fscore(data_train2, y_train))\n",
    "print('Recall', get_recall(data_train2, y_train))\n",
    "print('Precesion',get_precision(data_train2, y_train, debug = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Case 3: choosing randomly any value, pos>300 neg< 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train3=np.where(X_train_array_length >300, 0, 1)\n",
    "data_train3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fscore : 0.662437073305\n",
      "Recall 1.0\n",
      "Precesion 0.49525675397\n"
     ]
    }
   ],
   "source": [
    "print('Fscore :', get_fscore(data_train3, y_train))\n",
    "print('Recall', get_recall(data_train3, y_train))\n",
    "print('Precesion',get_precision(data_train3, y_train, debug = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Length for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([152, 141, 302, ..., 258, 167, 142], dtype=uint64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_array_length=X_test_array.sum(axis=1)\n",
    "X_test_array_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test1=np.where(X_test_array_length < 194, 0, 1)\n",
    "data_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fscore : 0.659937888199\n",
      "Recall 1.0\n",
      "Precesion 0.492468134415\n"
     ]
    }
   ],
   "source": [
    "print('Fscore :', get_fscore(data_test1, y_test))\n",
    "print('Recall', get_recall(data_test1, y_test))\n",
    "print('Precesion',get_precision(data_test1, y_test, debug = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Case two: pos < 194, neg> 194"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test2=np.where(X_test_array_length < 194, 1, 0)\n",
    "data_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fscore : 0.67138450372\n",
      "Recall 1.0\n",
      "Precesion 0.505326413548\n"
     ]
    }
   ],
   "source": [
    "print('Fscore :', get_fscore(data_test2, y_test))\n",
    "print('Recall', get_recall(data_test2, y_test))\n",
    "print('Precesion',get_precision(data_test2, y_test, debug = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Case 3: choosing randomly any value, pos>300 neg< 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test3=np.where(X_test_array_length  >300, 1, 0)\n",
    "data_test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fscore : 0.665219057351\n",
      "Recall 1.0\n",
      "Precesion 0.498373205742\n"
     ]
    }
   ],
   "source": [
    "print('Fscore :', get_fscore(data_test3, y_test))\n",
    "print('Recall', get_recall(data_test3, y_test))\n",
    "print('Precesion',get_precision(data_test3, y_test, debug = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### As you can see, all scores are very similar to each other, which means that disribution of data is very normal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive-Bayes Classifier\n"
     ]
    }
   ],
   "source": [
    "#initialize NB classifier\n",
    "print(\"Naive-Bayes Classifier\")\n",
    "nb = GaussianNB()\n",
    "#fit your classifier to training set\n",
    "nb = nb.fit(train_df, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As you saw above I was training my model with full data, but for prediction I use less data as my memory is not handling it\n",
    "y_pred1 = nb.predict(test_df[:15000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fscore : 0.915222562012\n",
      "Recall 1.0\n",
      "Precesion 0.843696162882\n"
     ]
    }
   ],
   "source": [
    "print('Fscore :', get_fscore(y_pred1, y_test[:15000]))\n",
    "print('Recall', get_recall(y_pred1, y_test[:15000]))\n",
    "print('Precesion',get_precision(y_pred1, y_test[:15000], debug = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5\n",
    "### Decision Tree Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree Classifier\n",
    "print(\"Decision Tree Classifier\")\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "dt = dt.fit(train_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#As you saw above I was training my model with full data, but for prediction I use less data as my memory is not handling it\n",
    "y_pred = dt.predict(test_df[:15000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fscore : 1.0\n",
      "Recall 1.0\n",
      "Precesion 1.0\n"
     ]
    }
   ],
   "source": [
    "print('Fscore :', get_fscore(y_pred, y_test[:15000]))\n",
    "print('Recall', get_recall(y_pred, y_test[:15000]))\n",
    "print('Precesion',get_precision(y_pred, y_test[:15000], debug = False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6\n",
    "\n",
    "As we can observe from all 5 models, the most accurate ones were Naive BAyes and Decision Tree. The other two self made assumptions unfortunately did not give good results if we look at our model evaluation metrics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mxnet\n",
      "  Using cached https://files.pythonhosted.org/packages/a4/3e/07f6d61d8e0a5d50c6f128791a617d7b222224c52dacba04855a0b6ecfe6/mxnet-1.5.0-py2.py3-none-win_amd64.whl\n",
      "Requirement already satisfied: numpy<1.17.0,>=1.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from mxnet) (1.16.4)\n",
      "Collecting requests<2.19.0,>=2.18.4 (from mxnet)\n",
      "  Using cached https://files.pythonhosted.org/packages/49/df/50aa1999ab9bde74656c2919d9c0c085fd2b3775fd3eca826012bef76d8c/requests-2.18.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from mxnet) (0.8.4)\n",
      "Collecting idna<2.7,>=2.5 (from requests<2.19.0,>=2.18.4->mxnet)\n",
      "  Using cached https://files.pythonhosted.org/packages/27/cc/6dd9a3869f15c2edfab863b992838277279ce92663d334df9ecf5106f5c6/idna-2.6-py2.py3-none-any.whl\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<2.19.0,>=2.18.4->mxnet) (2019.6.16)\n",
      "Collecting urllib3<1.23,>=1.21.1 (from requests<2.19.0,>=2.18.4->mxnet)\n",
      "  Using cached https://files.pythonhosted.org/packages/63/cb/6965947c13a94236f6d4b8223e21beb4d576dc72e8130bd7880f600839b8/urllib3-1.22-py2.py3-none-any.whl\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<2.19.0,>=2.18.4->mxnet) (3.0.4)\n",
      "Installing collected packages: idna, urllib3, requests, mxnet\n",
      "Successfully installed idna-2.6 mxnet-1.5.0 requests-2.18.4 urllib3-1.22\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --user mxnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gluonnlp\n",
      "  Downloading https://files.pythonhosted.org/packages/6e/2d/40c2ad37d74e5e9030064d73542b7df0f7df7ba98d47932874033cf03d79/gluonnlp-0.8.1.tar.gz (236kB)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from gluonnlp) (1.16.4)\n",
      "Building wheels for collected packages: gluonnlp\n",
      "  Building wheel for gluonnlp (setup.py): started\n",
      "  Building wheel for gluonnlp (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\Ibragim\\AppData\\Local\\pip\\Cache\\wheels\\3e\\e7\\3e\\9cdf8ad7fce112fde2f4a52604045e5dd80f84d645bedb70c7\n",
      "Successfully built gluonnlp\n",
      "Installing collected packages: gluonnlp\n",
      "Successfully installed gluonnlp-0.8.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gluonnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from mxnet import gluon\n",
    "from mxnet import nd\n",
    "import gluonnlp as nlp\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_simple = nlp.embedding.create('fasttext', source='wiki.simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['glove.42B.300d',\n",
       " 'glove.6B.100d',\n",
       " 'glove.6B.200d',\n",
       " 'glove.6B.300d',\n",
       " 'glove.6B.50d',\n",
       " 'glove.840B.300d',\n",
       " 'glove.twitter.27B.100d',\n",
       " 'glove.twitter.27B.200d',\n",
       " 'glove.twitter.27B.25d',\n",
       " 'glove.twitter.27B.50d']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.embedding.list_sources('glove')\n",
    "#We can  create vocabulary by using vocabulary of pre-trained word embeddings, such as GloVe. \n",
    "#Below are a few pre-trained file names under the GloVe word embedding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding file glove.6B.300d.npz is not found. Downloading from Gluon Repository. This may take some time.\n",
      "Downloading C:\\Users\\Ibragim\\.mxnet\\embedding\\glove\\glove.6B.300d.npz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/embeddings/glove/glove.6B.300d.npz...\n"
     ]
    }
   ],
   "source": [
    "#we use a smaller word embedding file, such as the 300-dimensional one\n",
    "glove_6b300d = nlp.embedding.create('glove', source='glove.6B.300d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we create vocabulary by using all the tokens from  pre trained glove:glove_6b50d\n",
    "vocab = nlp.Vocab(nlp.data.Counter(glove_6b300d.idx_to_token))\n",
    "vocab.set_embedding(glove_6b300d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to define cosine similarity\n",
    "from mxnet import nd\n",
    "def cos_sim(x, y):\n",
    "    return nd.dot(x, y) / (nd.norm(x) * nd.norm(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word Similarity\n",
    "def norm_vecs_by_row(x):\n",
    "    return x / nd.sqrt(nd.sum(x * x, axis=1) + 1E-10).reshape((-1,1))\n",
    "\n",
    "def get_knn(vocab, k, word):\n",
    "    word_vec = vocab.embedding[word].reshape((-1, 1))\n",
    "    vocab_vecs = norm_vecs_by_row(vocab.embedding.idx_to_vec)\n",
    "    dot_prod = nd.dot(vocab_vecs, word_vec)\n",
    "    indices = nd.topk(dot_prod.reshape((len(vocab), )), k=k+1, ret_typ='indices')\n",
    "    indices = [int(i.asscalar()) for i in indices]\n",
    "    # Remove unknown and input tokens.\n",
    "    return vocab.to_tokens(indices[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can  apply pre-trained word embeddings to the word analogy test\n",
    "def get_top_k_by_analogy(vocab, k, word1, word2, word3):\n",
    "    word_vecs = vocab.embedding[word1, word2, word3]\n",
    "    word_diff = (word_vecs[1] - word_vecs[0] + word_vecs[2]).reshape((-1, 1))\n",
    "    vocab_vecs = norm_vecs_by_row(vocab.embedding.idx_to_vec)\n",
    "    dot_prod = nd.dot(vocab_vecs, word_diff)\n",
    "    indices = nd.topk(dot_prod.reshape((len(vocab), )), k=k, ret_typ='indices')\n",
    "    indices = [int(i.asscalar()) for i in indices]\n",
    "    return vocab.to_tokens(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are measuring here accuracy of analogy cosine similarity \n",
    "#between vec(‘word1’)+vec(‘word2’)-vec(‘word3’) and vec(‘word4’).  \n",
    "def cos_sim_word_analogy(vocab, word1, word2, word3, word4):\n",
    "    words = [word1, word2, word3, word4]\n",
    "    vecs = vocab.embedding[words]\n",
    "    return cos_sim(vecs[1] - vecs[0] + vecs[2], vecs[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analogy Test 1 with pre trained  glove_6b300d\n",
    "\n",
    "###### Semantic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Analogy: ['brother']\n",
      "Top Analogy: ['euro']\n",
      "Top Analogy: ['<unk>']\n",
      "Top Analogy: ['tokyo']\n"
     ]
    }
   ],
   "source": [
    "# Question: mother, father, sister brother\n",
    "print( 'Top Analogy:', get_top_k_by_analogy(vocab, 1, 'mother', 'father', 'sister')) #right analogy\n",
    "# Question: Europe euro USA dollar \n",
    "print( 'Top Analogy:', get_top_k_by_analogy(vocab, 1, 'Europe', 'euro', 'USA')) #wrong prediction\n",
    "# Question: Detroit Michigan Sacramento California\n",
    "print( 'Top Analogy:', get_top_k_by_analogy(vocab, 1, 'Detroit', 'Michigan', 'Sacramento ')) #wrong prediction\n",
    "# Question: beijing, china, tokyo, japan\n",
    "print( 'Top Analogy:', get_top_k_by_analogy(vocab, 1, 'beijing', 'china', 'tokyo')) #wrong prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine sim: \n",
      "[0.80230254]\n",
      "<NDArray 1 @cpu(0)>\n",
      "Cosine sim: \n",
      "[1.0000001]\n",
      "<NDArray 1 @cpu(0)>\n",
      "Cosine sim: \n",
      "[nan]\n",
      "<NDArray 1 @cpu(0)>\n",
      "Cosine sim: \n",
      "[0.8107581]\n",
      "<NDArray 1 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "print('Cosine sim:', cos_sim_word_analogy(vocab,  'mother', 'father', 'sister', 'brother'))\n",
    "print('Cosine sim:', cos_sim_word_analogy(vocab,  'Europe', 'euro', 'USA', 'euro'))\n",
    "print('Cosine sim:', cos_sim_word_analogy(vocab,  'Detroit', 'Michigan', 'Sacramento', 'California'))\n",
    "print('Cosine sim:', cos_sim_word_analogy(vocab,  'beijing', 'china', 'tokyo', 'tokyo'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Syntactic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Analogy: ['amazingly']\n",
      "Top Analogy: ['honest']\n",
      "Top Analogy: ['worst']\n",
      "Top Analogy: ['went']\n"
     ]
    }
   ],
   "source": [
    "# Question:amazing amazingly rapid rapidly\n",
    "print( 'Top Analogy:', get_top_k_by_analogy(vocab, 1, 'amazing', 'amazingly', ' rapid')) #wrong prediction\n",
    "# Question: logical illogical honest dishonest\n",
    "print( 'Top Analogy:', get_top_k_by_analogy(vocab, 1, 'logical', 'illogical', 'honest')) #wrong prediction\n",
    "# Question: 'bad', 'worst', 'big', 'biggest'\n",
    "print( 'Top Analogy:', get_top_k_by_analogy(vocab, 1, 'bad', 'worst', 'big')) #wrong prediction\n",
    "# Question:'do', 'did', 'go', 'went'\n",
    "print( 'Top Analogy:',get_top_k_by_analogy(vocab, 1, 'do', 'did', 'go')) #right Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine sim: \n",
      "[0.4422674]\n",
      "<NDArray 1 @cpu(0)>\n",
      "Cosine sim: \n",
      "[0.6742419]\n",
      "<NDArray 1 @cpu(0)>\n",
      "Cosine sim: \n",
      "[0.6712073]\n",
      "<NDArray 1 @cpu(0)>\n",
      "Cosine sim: \n",
      "[0.77813184]\n",
      "<NDArray 1 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "print('Cosine sim:', cos_sim_word_analogy(vocab,  'amazing', 'amazingly', ' rapid', 'amazingly'))\n",
    "print('Cosine sim:', cos_sim_word_analogy(vocab,  'logical', 'illogical', 'honest', 'honest'))\n",
    "print('Cosine sim:', cos_sim_word_analogy(vocab,  'bad', 'worst', 'big', 'worst'))\n",
    "print('Cosine sim:', cos_sim_word_analogy(vocab,  'do', 'did', 'go', 'went'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analogy Test 2 with pre trained  glove_6b300d\n",
    "\n",
    "###### Semantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_6B50d = nlp.embedding.create('glove', source='glove.6B.50d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab2 = nlp.Vocab(nlp.data.Counter(glove_6B50d.idx_to_token))\n",
    "vocab2.set_embedding(glove_6B50d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Analogy: ['brother']\n"
     ]
    }
   ],
   "source": [
    "# Question: mother, father, sister brother\n",
    "print( 'Top Analogy:', get_top_k_by_analogy(vocab2, 1, 'mother', 'father', 'sister')) #right analogy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Analogy: ['euro']\n"
     ]
    }
   ],
   "source": [
    "# Question: Europe euro USA dollar \n",
    "print( 'Top Analogy:', get_top_k_by_analogy(vocab2, 1, 'Europe', 'euro', 'USA')) #wrong prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Analogy: ['<unk>']\n"
     ]
    }
   ],
   "source": [
    "# Question: Detroit Michigan Sacramento California\n",
    "print( 'Top Analogy:', get_top_k_by_analogy(vocab2, 1, 'Detroit', 'Michigan', 'Sacramento ')) #wrong prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Analogy: ['japan']\n"
     ]
    }
   ],
   "source": [
    "# Question: beijing, china, tokyo, japan\n",
    "print( 'Top Analogy:', get_top_k_by_analogy(vocab2, 1, 'beijing', 'china', 'tokyo')) #right prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Syntactic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Analogy: ['apppointed']\n"
     ]
    }
   ],
   "source": [
    "# Question:amazing amazingly rapid rapidly\n",
    "print( 'Top Analogy:', get_top_k_by_analogy(vocab2, 1, 'amazing', 'amazingly', ' rapid')) #wrong prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Analogy: ['irresponsible']\n"
     ]
    }
   ],
   "source": [
    "# Question: logical illogical honest dishonest\n",
    "print( 'Top Analogy:', get_top_k_by_analogy(vocab2, 1, 'logical', 'illogical', 'honest')) #wrong prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Analogy: ['biggest']\n"
     ]
    }
   ],
   "source": [
    "# Question: 'bad', 'worst', 'big', 'biggest'\n",
    "print( 'Top Analogy:', get_top_k_by_analogy(vocab2, 1, 'bad', 'worst', 'big')) #right prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Analogy: ['went']\n"
     ]
    }
   ],
   "source": [
    "# Question:'do', 'did', 'go', 'went'\n",
    "print( 'Top Analogy:',get_top_k_by_analogy(vocab2, 1, 'do', 'did', 'go')) #right Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Of course, due to limitations of my laptop memory capacity, I was not able to load larger pre trained embeddings like Google News, though I was able to really understand how word embeddings are  formed. It is interesting to note if I compare two results, higher dimensional embedding was less accurate then less dimensional. Also, I guess the size of vocabulary would play significant role as I can say that , may be because of limited wocabulary, two of the completed anology tests did  gave me expected result of at least 75% accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 8\n",
    "\n",
    "Word embedding is a distributed representation of words in a vector space. It involves a mathematical embedding from a space\n",
    "with one dimension per word to a continuous vector space with much lower dimension. Word embeddings greatly enhanced word representation. Vectorised presentation of words, however often fail to correctly recognize antonymous words like hot and cold, because of context similarity.  The main reason for this would be the fact that pre-trained word embeddings are trained from large amount of corpus where word distributions share similar contexts. This may provoke case that it would be difficult to discriminate antonyms from synonyms. Therefore, this problem should be resolved and now  a few papers are published to address it as tasks like semantic textual similarity will bring more accurate results if antonym-sensitive embeddings are created. \n",
    "\n",
    "[Dou, Z., Wei, W., & Wan, X. (2018). Improving Word Embeddings for Antonym Detection Using Thesauri and SentiWordNet. Natural Language Processing and Chinese Computing Lecture Notes in Computer Science, 67–79. doi: 10.1007/978-3-319-99501-4_6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['allow',\n",
       " 'leave',\n",
       " 'entering',\n",
       " 'must',\n",
       " 'able',\n",
       " 'stay',\n",
       " 'take',\n",
       " 'to',\n",
       " 'decide',\n",
       " 'supposed']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_knn(vocab, 10, 'enter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['increases',\n",
       " 'increased',\n",
       " 'increasing',\n",
       " 'decrease',\n",
       " 'reduction',\n",
       " 'reducing',\n",
       " 'reduced',\n",
       " 'growth',\n",
       " 'reduce',\n",
       " 'higher']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_knn(vocab, 10, 'increase') #wow there are a lot of mismatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 9 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First tripler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Analogy: ['summer']\n"
     ]
    }
   ],
   "source": [
    "#Season to Month\n",
    "print( 'Top Analogy:', get_top_k_by_analogy(vocab, 1, 'july', 'summer', ' January')) #wrong prediction, winter is right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Analogy: ['chicken']\n"
     ]
    }
   ],
   "source": [
    "#animal to its production\n",
    "print( 'Top Analogy:', get_top_k_by_analogy(vocab,1, 'cow', 'milk', 'chicken')) #wrong prediction, egg is right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Analogy: ['vegetable']\n"
     ]
    }
   ],
   "source": [
    "#food to category \n",
    "print( 'Top Analogy:', get_top_k_by_analogy(vocab, 1, 'potatoe', 'vegetable', ' apple')) #wrong prediction, fruit is right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Tripler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Analogy: ['foodies']\n"
     ]
    }
   ],
   "source": [
    "#Season to Month\n",
    "print( 'Top Analogy:', get_top_k_by_analogy(vocab2, 1, 'july', 'summer', ' January')) #wrong prediction, winter is right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Analogy: ['sauce']\n"
     ]
    }
   ],
   "source": [
    "#animal to its production\n",
    "print( 'Top Analogy:', get_top_k_by_analogy(vocab2,1, 'cow', 'milk', 'chicken')) #wrong prediction, egg is right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Analogy: ['vegetable']\n"
     ]
    }
   ],
   "source": [
    "#food to category \n",
    "print( 'Top Analogy:', get_top_k_by_analogy(vocab2, 1, 'potatoe', 'vegetable', ' apple')) #wrong prediction, fruit is right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "[1] Yoshua Bengio, Ducharme Rejean &Vincent Pascal. A Neural Probabilistic Language Model. 2001. https://papers.nips.cc/paper/1839-a-neural-probabilistic-language-model.pdf\n",
    "\n",
    "[2] Yoshua Bengio, Ducharme Rejean, Vincent Pascal & Janvin Christian. A Neural Probabilistic Language Model. March 2003. http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf\n",
    "\n",
    "[3] Collobert Ronan, & Weston Jason. A Unified Architecture for Natural Language Processing: Deep Neural Networks with Multitask Learning. 2008. https://ronan.collobert.com/pub/matos/2008_nlp_icml.pdf\n",
    "\n",
    "[4] Tomas Mikolov, Greg Corrado, Kai Chen & Jeffrey Dean. Efficient Estimation of Word Representations in Vector Space. September 2013. https://arxiv.org/pdf/1301.3781.pdf\n",
    "\n",
    "[5] Gluon-nlp.mxnet.io. (2019). Pre-trained Word Embeddings — gluonnlp 0.8.1 documentation. [online] Available at: https://gluon-nlp.mxnet.io/examples/word_embedding/word_embedding.html [Accessed 7 Oct. 2019]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
